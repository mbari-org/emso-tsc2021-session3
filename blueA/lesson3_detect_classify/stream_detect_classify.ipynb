{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ![alt text](https://www.mbari.org/wp-content/uploads/2014/11/logo-mbari-3b.png \"MBARI\")\n",
    "\n",
    "  <div align=\"left\">Copyright (c) 2021, MBARI</div>\n",
    "\n",
    "  * Distributed under the terms of the GPL License\n",
    "  * Maintainer: dcline@mbari.org\n",
    "  * Authors: Danelle Cline dcline@mbari.org, John Ryan ryjo@mbari.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blue A Stream Detection\n",
    "\n",
    "This notebook demonstrates how to predict blue A calls on a spectrogram incrementally, leveraging PCEN streaming.  This is useful when an audio file is large,  or if streaming data directly from a hydrophone. This is an alternative to using BLEDs for detection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies\n",
    "\n",
    "First, let's install dependencies and include all packages used in this tutorial. This only needs to be done once for the duration of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install oceansoundscape==1.1.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "import datetime\n",
    "import glob\n",
    "import numpy as np\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import soundfile as sf\n",
    "import scipy\n",
    "import sklearn\n",
    "import shutil\n",
    "import librosa as librosa\n",
    "import librosa.display as display \n",
    "from librosa.display import specshow, waveplot\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import requests\n",
    "import timeit\n",
    "import json\n",
    "from numpy.lib import stride_tricks\n",
    "import io\n",
    "import pandas as pd\n",
    "import dateutil.parser\n",
    "from scipy.signal import find_peaks\n",
    "from pathlib import Path\n",
    "from oceansoundscape.spectrogram import conf, colormap\n",
    "from oceansoundscape.spectrogram.utils import ImageUtils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local data store\n",
    "\n",
    "Let's set the path to the data here where we want to store the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path.cwd().parent.parent / 'data'\n",
    "if not data_path.exists():\n",
    "    data_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, download an audio file to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's download the data used in this notebook\n",
    "def fetch(file_path:Path):\n",
    "    \"\"\"\n",
    "    Utility to fetch a wav file from either a local file system or an S3 bucket\n",
    "    \"\"\" \n",
    "    s3 = boto3.resource('s3',\n",
    "        aws_access_key_id='',\n",
    "        aws_secret_access_key='',\n",
    "        config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "    if not file_path.exists():\n",
    "        print('Downloading')\n",
    "        s3.Bucket('emso-tsc2021-session3-eu-west-3').download_file(file_path.name, file_path.as_posix())\n",
    "        print(f'Done downloading {file_path}') \n",
    "    \n",
    "# wav_path = data_path / 'blue_A_stream.wav' # shorter 5 minute example\n",
    "wav_path = data_path / 'MARS-20171101T000000Z-10min-2kHz.wav' \n",
    "fetch(wav_path)\n",
    "samples, sample_rate = sf.read(wav_path.as_posix())\n",
    "nsec = (samples.size)/sample_rate # number of seconds in vector\n",
    "print(f'Read {nsec} seconds of data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCEN Streaming\n",
    "\n",
    "Here, can use the streaming IO with librosa.pcen to do dynamic per-channel energy normalization (PCEN) on a spectrogram incrementally. \n",
    "\n",
    "First, set up the block reader to work on audio segments at least the length of an expected call, overlapping prediction by 75% with adjacent frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The optimum configuration for the call spectrogram generation\n",
    "# is defined in the oceanscoundscape package based on extensive\n",
    "# hyper parameter sweeps. These need to match those used to train the model\n",
    "blue_a_conf = conf.CONF_DICT['blueA']\n",
    "\n",
    "# this is a global for all call types\n",
    "fft_overlap = conf.OVERLAP \n",
    "\n",
    "# fft window and overlap - should be the same used in training the model\n",
    "num_fft = blue_a_conf['num_fft']\n",
    "hop_length = int(num_fft * (1 - fft_overlap)) \n",
    "call_duration_secs = blue_a_conf['duration_secs'] \n",
    "secs_per_frame = hop_length / sample_rate\n",
    "\n",
    "# the axis to blur during spectrogram generation; freq or time or empty for no blurring\n",
    "# should be the same as used in training\n",
    "blur_axis = blue_a_conf['blur_axis'] \n",
    "\n",
    "# Block 20x the length of a call window\n",
    "block_length = int(20*call_duration_secs/secs_per_frame)\n",
    " \n",
    "# Overlap window for prediction by 75% \n",
    "pred_overlap = .75\n",
    "overlap = int(call_duration_secs*pred_overlap/secs_per_frame)\n",
    " \n",
    "window_size = call_duration_secs/secs_per_frame\n",
    "step_size = window_size - overlap\n",
    "num_segments = int(block_length/step_size)\n",
    "\n",
    "freq_min = blue_a_conf['low_freq']\n",
    "freq_max =  blue_a_conf['high_freq']\n",
    "\n",
    "# PCEN parameters\n",
    "pcen_gain = conf.PCEN_GAIN\n",
    "pcen_bias = conf.PCEN_BIAS\n",
    "pcen_tc = conf.PCEN_TIME_CONSTANT\n",
    "num_mels = blue_a_conf['num_mels']\n",
    "\n",
    "def stream_init(filename):\n",
    "    \"\"\"\n",
    "    Utility function to reinialize the stream\n",
    "    \"\"\"\n",
    "    return librosa.stream(filename, block_length=block_length,\n",
    "                            frame_length=num_fft,\n",
    "                            hop_length=hop_length,\n",
    "                            mono=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Striding\n",
    "\n",
    "After computing the spectrogram one could simply run a non-overlapping window across the spectrogram, but that could miss a call if it landed on the boundary of a window.  To remedy this, striding the spectrogram with overlapping segments is needed which is simplified with the method below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_views(arr, win_size, step_size, writeable = False):\n",
    "  \"\"\"\n",
    "  # Credit to Kevin Urban's blog for the code below to simplify striding\n",
    "  https://krbnite.github.io/Memory-Efficient-Windowing-of-Time-Series-Data-in-Python-3-Memory-Strides-in-Pandas/\n",
    "  arr: any 2D array whose columns are distinct variables and \n",
    "    rows are data records at some timestamp t\n",
    "  win_size: size of data window (given in data points along record/time axis)\n",
    "  step_size: size of window step (given in data point along record/time axis)\n",
    "  writable: if True, elements can be modified in new data structure, which will affect\n",
    "    original array (defaults to False)\n",
    "  \n",
    "  Note that step_size is related to window overlap (overlap = win_size - step_size), in \n",
    "  case you think in overlaps.\n",
    "  \"\"\"\n",
    "  \n",
    "  # If DataFrame, use only underlying NumPy array\n",
    "  if type(arr) == type(pd.DataFrame()):\n",
    "    arr = arr.values\n",
    "  \n",
    "  # Compute Shape Parameter for as_strided\n",
    "  n_records = arr.shape[0]\n",
    "  n_columns = arr.shape[1]\n",
    "  remainder = (n_records - win_size) % step_size \n",
    "  # Note  - bug fix here - add 2 not 1 as in the blog\n",
    "  num_windows = 2 + int((n_records - win_size - remainder) / step_size) \n",
    "  shape = (num_windows, win_size, n_columns)\n",
    "  \n",
    "  # Compute Strides Parameter for as_strided\n",
    "  next_win = step_size * arr.strides[0]\n",
    "  next_row, next_col = arr.strides\n",
    "  strides = (next_win, next_row, next_col)\n",
    "    \n",
    "  # print(f'shape {shape} strides {strides}')\n",
    "\n",
    "  new_view_structure = stride_tricks.as_strided(\n",
    "    arr,\n",
    "    shape = shape,\n",
    "    strides = strides,\n",
    "    writeable = writeable,\n",
    "  )\n",
    "  return new_view_structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Visualize overlapping spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the PCEN filter delays to steady state\n",
    "zi = None\n",
    "stream = stream_init(wav_path.as_posix())\n",
    "\n",
    "# Initialize figure with subplots to visualize the overlap in the first block\n",
    "fig2, axes = plt.subplots(21, 1)\n",
    "fig2.set_size_inches(6, 12)\n",
    "\n",
    "for y_block in stream:\n",
    "    \n",
    "    D = librosa.feature.melspectrogram(sklearn.preprocessing.minmax_scale(y_block, feature_range=((-2 ** 31), (2 ** 31))), \n",
    "            sr=sample_rate, center=True, hop_length=hop_length, power=1, \n",
    "                                       n_mels=num_mels, fmin=freq_min, fmax=freq_max)\n",
    "\n",
    "    # Compute PCEN on the mel spectrum using initial delays (zi)\n",
    "    P, zi =  librosa.pcen((2**31)*D, sr=sample_rate, hop_length=hop_length, gain=pcen_gain, bias=pcen_bias, \n",
    "                          time_constant=pcen_tc, zi=zi, return_zf=True)\n",
    "    \n",
    "    # Create strided view\n",
    "    strided = make_views(P.transpose(), win_size=int(window_size), step_size=int(step_size))\n",
    "     \n",
    "    librosa.display.specshow(P, sr=sample_rate, fmin=freq_min, fmax=freq_max, cmap=colormap.parula_map,\n",
    "                         hop_length=hop_length, x_axis='time', y_axis='mel', ax=axes[0])\n",
    "    \n",
    "    # Display the first 20 overlapping segments\n",
    "    for i, s in enumerate(strided):\n",
    "        if i > 19:\n",
    "            break\n",
    "        librosa.display.specshow(utils.smooth(s.transpose(), blur_axis), sr=sample_rate, fmin=freq_min, fmax=freq_max, \n",
    "                                 cmap=colormap.parula_map, hop_length=hop_length, x_axis='time', \n",
    "                                 y_axis='mel', ax=axes[i+1]) \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'pacific-sound-models'\n",
    "model_filename = 'bluewhale-a-resnet50-2021-09-22-21-05-23-858.tar.gz' \n",
    "\n",
    "# only download if needed\n",
    "if not Path(model_filename).exists(): \n",
    "    print(f'Downloading...') \n",
    "    s3.Bucket(bucket).download_file(key, model_filename)\n",
    "\n",
    "# Alternatively, it can be downloaded directly in SageMaker with\n",
    "# !aws s3 cp s3://{bucket}/{key} . \n",
    " \n",
    "print(f'Uncompressing')\n",
    "!tar -xf {model_filename}\n",
    "print(f'Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open('1/config.json'))\n",
    "image_mean = np.asarray(config[\"image_mean\"])\n",
    "image_std = np.asarray(config[\"image_std\"])\n",
    "print(f\"Labels {config['classes']}\")\n",
    "print(f\"Training image mean: {image_mean}\")\n",
    "print(f\"Training image std: {image_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the classifier over each optimized segment\n",
    "\n",
    "Here, we take the pcen computed segment, further preprocess it in the same manner the training data was preprocessed. This preprocessing applies the same colormap, smooths the image in the frequency domain, then denoises the colorized spectrogram in the color domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(file_path:Path, quiet=False):\n",
    "    zi = None\n",
    "    stream = stream_init(file_path.absolute())\n",
    "    batch_size = 1\n",
    "    secs = 0\n",
    "\n",
    "    df = pd.DataFrame(columns=[\"date_time\", \"score_baf\", \"score_bat\"]) \n",
    "    # splits out 20171101T000000Z from MARS-20171101T000000Z-2kHz.wav\n",
    "    s = file_path.stem.split('-')[1] \n",
    "    # convert to a datetime object\n",
    "    start_dt = datetime.datetime.strptime(s, '%Y%m%dT%H%M%SZ')\n",
    "\n",
    "    start_time = timeit.default_timer()\n",
    "    print(f'Processing {file_path}')\n",
    "    for y_block in stream:\n",
    "\n",
    "        D = librosa.feature.melspectrogram(sklearn.preprocessing.minmax_scale(y_block, feature_range=(-2 ** 31, 2 ** 31)), \n",
    "                                           sr = sample_rate, \n",
    "                                           center = False, \n",
    "                                           hop_length = hop_length, \n",
    "                                           power = 1, \n",
    "                                           n_mels = num_mels, \n",
    "                                           fmin = freq_min, \n",
    "                                           fmax = freq_max)\n",
    "\n",
    "        # Compute PCEN on the mel spectrum using initial delays (zi)\n",
    "        P, zi =  librosa.pcen((2**31)*D, \n",
    "                              sr = sample_rate, \n",
    "                              hop_length = hop_length, \n",
    "                              gain = pcen_gain, \n",
    "                              bias = pcen_bias, \n",
    "                              time_constant = pcen_tc, \n",
    "                              zi = zi, \n",
    "                              return_zf = True)\n",
    "\n",
    "        # Create strided view\n",
    "        strided = make_views(P.transpose(), win_size=int(window_size), step_size=int(step_size)) \n",
    "\n",
    "        for i, s in enumerate(strided): \n",
    "            image_path = Path(f'block{y_block[0]}_stride{i}.jpg')\n",
    "\n",
    "            strided_smoothed = utils.smooth(s.transpose(), blur_axis)\n",
    "            strided_colored = utils.colorizeDenoise(strided_smoothed, image_path)\n",
    "            image_bgr = cv2.imread(image_path.as_posix())\n",
    "            image = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # normalize with the same parameters used in training\n",
    "            image_float = np.asarray(image).astype('float32')\n",
    "            image_float = image_float / 255.0\n",
    "            image_float = (image_float - image_mean) / image_std\n",
    "\n",
    "            image = np.concatenate([image_float[np.newaxis, :, :]] * batch_size)\n",
    "            tensor_out = model(image)\n",
    "            score_baf, score_bat = tensor_out.numpy()[0]\n",
    "\n",
    "            date_time = start_dt + datetime.timedelta(microseconds=int(secs*1e6))\n",
    "\n",
    "            if not quiet:\n",
    "                print(f'Processing segment {i} bat {score_bat} baf {score_baf} start_time {date_time}')\n",
    "            secs += step_size*secs_per_frame\n",
    "\n",
    "            df = df.append({'date_time': date_time, \n",
    "                            'score_baf': score_baf, \n",
    "                            'score_bat': score_bat}, \n",
    "                           ignore_index=True)\n",
    "\n",
    "            # uncomment the following line to save the classification image along with an encoded score in the filename\n",
    "            # this can be useful for visual browsing\n",
    "            # shutil.copy2(image_path, f'block{y_block[0]}_stride{i}_{int(score_bat*100):02}.jpg')\n",
    "\n",
    "            # remove the image \n",
    "            image_path.unlink()\n",
    "\n",
    "    total_seconds = timeit.default_timer() - start_time \n",
    "    print(f' {file_path.name} done. Processed {secs} seconds of data in {total_seconds} seconds')\n",
    "    \n",
    "    # Save to a csv file in the same directory as this notebook for later use\n",
    "    df.to_csv(Path.cwd() / f'{file_path.name}.csv') \n",
    "    \n",
    "    return df\n",
    "    \n",
    "df = process(wav_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot model scores\n",
    "\n",
    "Here, we plot the true scores with a peak detector to locate the calls.  These peaks serve as a proxy for the call counts in the time-series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out only the higher scores\n",
    "df_true = df[df['score_bat'] > 0.70]\n",
    "\n",
    "# Find peaks at least as far apart as the typical duration of a call\n",
    "call_step = round(call_duration_secs/(step_size*secs_per_frame))\n",
    "peaks = find_peaks(df_true.score_bat.values, distance=call_step)\n",
    "\n",
    "fig = plt.figure(figsize=(32, 8))\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 1])\n",
    " \n",
    "D = librosa.feature.melspectrogram(sklearn.preprocessing.minmax_scale(samples, feature_range=(-2 ** 31, 2 ** 31)), \n",
    "                                   sr = sample_rate, \n",
    "                                   center = False, \n",
    "                                   hop_length = hop_length, \n",
    "                                   power = 1, \n",
    "                                   n_mels = num_mels, \n",
    "                                   fmin = freq_min, \n",
    "                                   fmax = freq_max)\n",
    " \n",
    "P =  librosa.pcen((2**31)*D, \n",
    "                  sr = sample_rate, \n",
    "                  hop_length = hop_length, \n",
    "                  gain = pcen_gain, \n",
    "                  bias = pcen_bias, \n",
    "                  time_constant = pcen_tc)\n",
    " \n",
    "plt.subplot(gs[0])\n",
    "librosa.display.specshow(utils.smooth(P, blur_axis), \n",
    "                         sr = sample_rate, \n",
    "                         fmin = freq_min, \n",
    "                         fmax = freq_max, \n",
    "                         cmap = colormap.parula_map, \n",
    "                         hop_length = hop_length, \n",
    "                         x_axis='time', y_axis='mel')\n",
    " \n",
    "plt.subplot(gs[1])\n",
    "plt.plot(df_true.date_time.values, df_true.score_bat, 'o', color='grey', markersize=10)\n",
    "plt.plot(df_true.date_time.values[peaks[0]], df_true.score_bat.values[peaks[0]], \"x\", color='red', markersize=15)\n",
    "plt.ylabel('Model Blue A True Score')\n",
    "plt.xlabel('Seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch processing\n",
    "\n",
    "Let's process one week of data, running the model across each day, finding peaks for each call.  The week of November 12 - 18, 2017 is a good week, with strong variation in the call index and no recording gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = range(17,20)\n",
    "year = 2017\n",
    "month = 11  \n",
    "\n",
    "# for d in days:\n",
    "#     filename = data_path / f'MARS-201711{d}T000000Z-2kHz.wav'\n",
    "#     fetch(filename) \n",
    "#     process(filename, quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all the results and filter only high scoring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the test file - we don't want to include this in the time-series\n",
    "%rm MARS-20171101T000000Z-10min-2kHz.wav.csv\n",
    "\n",
    "files = Path.cwd().glob('*.csv')\n",
    "df = pd.DataFrame()\n",
    "for f in files:\n",
    "    print(f)\n",
    "    df = df.append(pd.read_csv(f.absolute()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iso_date(date_string):\n",
    "    return dateutil.parser.parse(date_string)\n",
    "\n",
    "df['call_start'] = df.apply(lambda x: iso_date(x['date_time']), axis=1)\n",
    "\n",
    "# Filter out only the higher scores\n",
    "df_70 = df[df['score_bat'] > 0.70]\n",
    " \n",
    "# Find peaks at least as far apart as the typical duration of a call\n",
    "print('Finding peaks...')\n",
    "call_step = round(call_duration_secs/(step_size*secs_per_frame))\n",
    "peaks = find_peaks(df_70.score_bat.values, distance=call_step)\n",
    "print('Done')\n",
    "\n",
    "# Create a dataframe with the peaks\n",
    "df_calls = pd.DataFrame(index=peaks[0])\n",
    "df_calls['date_time'] = df_70.date_time.values[peaks[0]]\n",
    "df_calls['calls'] = 1\n",
    "df_calls.index = df_calls.apply(lambda x: iso_date(x['date_time']), axis=1)\n",
    "df_calls = df_calls.drop(columns=['date_time'])\n",
    "df_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and plot hourly binned data for the week "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_hourly = df_calls.resample('H').sum()\n",
    "df_calls_hourly.to_csv('HourlyCNN-12-18Nov2017')\n",
    "len(df_calls_hourly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 3))\n",
    " \n",
    "ax.scatter(df_calls_hourly.resample('H').sum().index.values,\n",
    "           df_calls_hourly.resample('H').sum()['calls'],\n",
    "           color='blue')\n",
    "\n",
    "# Set title and labels for axes\n",
    "ax.set(xlabel=\"Date\",\n",
    "       ylabel=\"Total calls detected > 0.7)\",\n",
    "       title=\"Blue whale A Calls Hourly 12-18Nov2017\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emso-tsc2021-session3",
   "language": "python",
   "name": "emso-tsc2021-session3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
